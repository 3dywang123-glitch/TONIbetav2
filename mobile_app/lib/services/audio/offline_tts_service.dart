import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:flutter/services.dart';
import 'package:path_provider/path_provider.dart';
import 'package:sherpa_onnx/sherpa_onnx.dart' as sherpa;
import 'package:audioplayers/audioplayers.dart';

class OfflineTtsService {
  static final OfflineTtsService _instance = OfflineTtsService._internal();
  factory OfflineTtsService() => _instance;
  OfflineTtsService._internal();

  sherpa.OfflineTts? _tts;
  final AudioPlayer _player = AudioPlayer();
  bool _isReady = false;
  String? _initError;

  // ğŸ§ é€‰è§’é…ç½® (AIShell3 ID èŒƒå›´ 0-173)
  final int _secretaryId = 167; // ç”œç¾
  final int _expertId = 120;    // æ²‰ç¨³

  bool get isReady => _isReady;
  String? get initError => _initError;

  Future<void> init() async {
    if (_isReady) return;
    debugPrint("ğŸ“¦ [OfflineTTS] æ­£åœ¨è£…è½½æˆ˜æœ¯è¯­éŸ³æ¨¡å‹...");
    _initError = null;

    try {
      // 1. æ‹·è´æ ¸å¿ƒæ–‡ä»¶
      String modelPath = await _copyAssetToLocal('assets/model/vits-aishell3.onnx');
      String tokensPath = await _copyAssetToLocal('assets/model/tokens_tts.txt');
      String lexiconPath = await _copyAssetToLocal('assets/model/lexicon.txt');
      
      // 2. æ‹·è´è§„åˆ™æ–‡ä»¶ (è®©å®ƒèƒ½è¯»æ‡‚ "1998å¹´")
      String rulePath = await _copyAssetToLocal('assets/model/rule.far');
      await _copyAssetToLocal('assets/model/date.fst');
      await _copyAssetToLocal('assets/model/number.fst');
      await _copyAssetToLocal('assets/model/phone.fst');
      await _copyAssetToLocal('assets/model/new_heteronym.fst');

      // 3. é…ç½®å¼•æ“
      final config = sherpa.OfflineTtsConfig(
        model: sherpa.OfflineTtsModelConfig(
          vits: sherpa.OfflineTtsVitsModelConfig(
            model: modelPath,
            lexicon: lexiconPath,
            tokens: tokensPath,
          ),
          numThreads: 2,
          debug: false,
          provider: 'cpu', // æ‰‹æœºç«¯ç”¨ CPU
        ),
        ruleFsts: rulePath, // åŠ è½½è§„åˆ™
      );

      _tts = sherpa.OfflineTts(config);
      _isReady = true;
      debugPrint("ğŸš€ [OfflineTTS] å¼•æ“å°±ç»ªï¼");
    } catch (e) {
      _initError = e.toString();
      debugPrint("âŒ [OfflineTTS] åˆå§‹åŒ–å¤±è´¥: $e");
    }
  }

  /// è¯´è¯æ ¸å¿ƒæ–¹æ³•
  Future<void> speak(String text, {required bool isSecretary}) async {
    if (!_isReady || _tts == null) {
      debugPrint("âš ï¸ å¼•æ“æœªå°±ç»ª");
      return;
    }
    
    // åœæ­¢æ­£åœ¨æ’­æ”¾çš„å£°éŸ³
    await _player.stop();

    int sid = isSecretary ? _secretaryId : _expertId;
    double speed = isSecretary ? 1.1 : 0.9; // è¯­é€Ÿè°ƒæ•´

    debugPrint("ğŸ”Š ç”Ÿæˆä¸­ ($sid): $text");
    
    try {
      // 1. ç”ŸæˆåŸå§‹éŸ³é¢‘æ•°æ® (PCM Float32)
      final audio = _tts!.generate(text: text, sid: sid, speed: speed);
      
      // 2. è½¬æ¢ä¸º WAV æ ¼å¼ (å…³é”®æ­¥éª¤)
      // Sherpa è¾“å‡ºæ˜¯ sampleRate=22050 çš„å•å£°é“éŸ³é¢‘
      final wavBytes = _createWavHeader(audio.samples, audio.sampleRate);

      // 3. å†™å…¥ä¸´æ—¶æ–‡ä»¶
      final tempDir = await getTemporaryDirectory();
      final tempFile = File('${tempDir.path}/temp_speech.wav');
      await tempFile.writeAsBytes(wavBytes);

      // 4. æ’­æ”¾
      await _player.play(DeviceFileSource(tempFile.path));
    } catch (e) {
      debugPrint("âŒ TTS ç”Ÿæˆå¤±è´¥: $e");
    }
  }

  Future<void> stop() async {
    await _player.stop();
  }

  /// è¾…åŠ©ï¼šæŠŠ Assets æ‹·è´åˆ°æœ¬åœ°æ²™ç›’
  Future<String> _copyAssetToLocal(String assetPath) async {
    final docDir = await getApplicationDocumentsDirectory();
    final fileName = assetPath.split('/').last;
    final file = File('${docDir.path}/$fileName');
    if (!await file.exists()) {
      final data = await rootBundle.load(assetPath);
      final bytes = data.buffer.asUint8List();
      await file.writeAsBytes(bytes, flush: true);
    }
    return file.path;
  }

  /// æ ¸å¿ƒé»‘ç§‘æŠ€ï¼šæ‰‹åŠ¨æ„å»º WAV æ–‡ä»¶å¤´
  /// è®©æ’­æ”¾å™¨èƒ½å¬æ‡‚ Raw Data
  Uint8List _createWavHeader(Float32List samples, int sampleRate) {
    int numSamples = samples.length;
    int numChannels = 1;
    int bitsPerSample = 16;
    
    int byteRate = sampleRate * numChannels * bitsPerSample ~/ 8;
    int blockAlign = numChannels * bitsPerSample ~/ 8;
    int subChunk2Size = numSamples * numChannels * bitsPerSample ~/ 8;
    int chunkSize = 36 + subChunk2Size;

    final header = ByteData(44);
    
    // RIFF chunk
    _writeString(header, 0, 'RIFF');
    header.setUint32(4, chunkSize, Endian.little);
    _writeString(header, 8, 'WAVE');

    // fmt chunk
    _writeString(header, 12, 'fmt ');
    header.setUint32(16, 16, Endian.little); // Subchunk1Size
    header.setUint16(20, 1, Endian.little); // AudioFormat (1 = PCM)
    header.setUint16(22, numChannels, Endian.little);
    header.setUint32(24, sampleRate, Endian.little);
    header.setUint32(28, byteRate, Endian.little);
    header.setUint16(32, blockAlign, Endian.little);
    header.setUint16(34, bitsPerSample, Endian.little);

    // data chunk
    _writeString(header, 36, 'data');
    header.setUint32(40, subChunk2Size, Endian.little);

    // Convert Float32 samples (-1.0 to 1.0) to Int16 (-32768 to 32767)
    final pcmData = Int16List(numSamples);
    for (int i = 0; i < numSamples; i++) {
      double s = samples[i];
      if (s > 1.0) s = 1.0;
      if (s < -1.0) s = -1.0;
      pcmData[i] = (s * 32767).toInt();
    }

    final wavBytes = Uint8List(44 + pcmData.lengthInBytes);
    wavBytes.setRange(0, 44, header.buffer.asUint8List());
    wavBytes.setRange(44, wavBytes.length, pcmData.buffer.asUint8List());

    return wavBytes;
  }

  void _writeString(ByteData data, int offset, String value) {
    for (int i = 0; i < value.length; i++) {
      data.setUint8(offset + i, value.codeUnitAt(i));
    }
  }
}

